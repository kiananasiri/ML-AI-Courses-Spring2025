{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import re\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# پیش‌بینی هشتگ در توییتر با استفاده از Naive Bayes و CAR\n",
    "\n",
    "برای این تمرین از سه روش مختلف برای پیش‌بینی هشتگ‌های مناسب برای توییت‌ها استفاده شده است:\n",
    "\n",
    "1. الگوریتم Naive Bayes کتابخانه sklearn  بر اساس بردارهای تعبیه\n",
    "\n",
    "2. الگوریتم Naive Bayes بر اساس احتمالات\n",
    "\n",
    "3. قوانین  (Class Association Rules - CAR)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## پیش پردازش\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "دیتای مورد استفاده در این تمرین، پیش‌تر در تکلیف قبلی اماده شده است؛ مجموعه‌داده‌ی مربوطه به‌صورت یک فایل سی اس وی بوده و شامل متن ۵۰۰۰ توییت می‌باشد\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df = pd.read_csv('./texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>preprocess_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>هدف من پیدا کردن ایران ستیزان بود که شما رو یافتم \\r\\nحالا شما از پشت لباس پادشاهی دوست بیا بیرون چون طرفداران پادشاهی… https://t.co/ZKXhxrtVZU</td>\n",
       "      <td>هدف من پیدا کردن ایران ستیزان بود که شما رو یافتم حالا شما از پشت لباس پادشاهی دوست بیا بیرون چون طرفداران پادشاهی</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@reise_ghabile ظهر شمام بخیر</td>\n",
       "      <td>ظهر شمام بخیر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>دوست پسر خلبان کجا میفروخن؟</td>\n",
       "      <td>دوست پسر خلبان کجا میفروخن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>@HoseinMr007 خب اونجا زندگی میکنیم</td>\n",
       "      <td>خب اونجا زندگی می‌کنیم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @debianstable1: صبحا که میخوان منو از خواب بیدار کنن... https://t.co/ZOLx1KOqTW</td>\n",
       "      <td>صبحا که میخوان منو از خواب بیدار کنن</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0           0   \n",
       "1           1   \n",
       "2           2   \n",
       "3           3   \n",
       "4           4   \n",
       "\n",
       "                                                                                                                                              text  \\\n",
       "0  هدف من پیدا کردن ایران ستیزان بود که شما رو یافتم \\r\\nحالا شما از پشت لباس پادشاهی دوست بیا بیرون چون طرفداران پادشاهی… https://t.co/ZKXhxrtVZU   \n",
       "1                                                                                                                     @reise_ghabile ظهر شمام بخیر   \n",
       "2                                                                                                                      دوست پسر خلبان کجا میفروخن؟   \n",
       "3                                                                                                               @HoseinMr007 خب اونجا زندگی میکنیم   \n",
       "4                                                               RT @debianstable1: صبحا که میخوان منو از خواب بیدار کنن... https://t.co/ZOLx1KOqTW   \n",
       "\n",
       "                                                                                                     preprocess_texts  \n",
       "0  هدف من پیدا کردن ایران ستیزان بود که شما رو یافتم حالا شما از پشت لباس پادشاهی دوست بیا بیرون چون طرفداران پادشاهی  \n",
       "1                                                                                                       ظهر شمام بخیر  \n",
       "2                                                                                          دوست پسر خلبان کجا میفروخن  \n",
       "3                                                                                              خب اونجا زندگی می‌کنیم  \n",
       "4                                                                                صبحا که میخوان منو از خواب بیدار کنن  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### تابع استخراج هشتگ‌ها\n",
    "\n",
    "`extract_hashtags`: این تابع هشتگ‌ها را از متن توییت استخراج می‌کند\n",
    "- ورودی: متن توییت\n",
    "- خروجی: لیستی از هشتگ‌های موجود در متن\n",
    "- از عبارات منظم (regex) برای پیدا کردن کلمات بعد از علامت # استفاده می‌کند\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hashtags(text):\n",
    "    \"\"\"Extract hashtags from text\"\"\"\n",
    "    return re.findall(r'#(\\w+)', text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### تابع  پیش‌پردازش متن\n",
    "\n",
    "`preprocess_text`: این تابع متن توییت را پاک‌سازی و نرمال‌سازی می‌کند\n",
    "- حذف لینک‌ها\n",
    "- حذف کاراکترهای خاص\n",
    "- حذف فاصله‌های اضافی\n",
    "- حذف منشن‌ها (@username)\n",
    "- نگهداری فاصله"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and preprocess text\"\"\"\n",
    "    text = text.lower()\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+|(\\S\\.com)+','', text) \n",
    "     # Remove mentions and RT(retweet) lables\n",
    "    text = re.sub(r'@[\\w]+', '', text)\n",
    "    text = re.sub(r'(rt :)+|[؟.!=\"،]+|[@\\r\\n\\t()*&^\\%$!:…rt]+', '', text)\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^\\u0621-\\u0628\\u062A-\\u063A\\u0641-\\u0642\\u0644-\\u0648\\u064E-\\u0651\\u0655\\u067E\\u0686\\u06A9\\u06AF\\u06BE\\u06CC\\u200C\\u200F ]+$/', '', text)\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'[ ]{2,}', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### انجام پیش پردازش متن و استخراج هشتگ ها بر روی دیتا\n",
    "   - هشتگ‌های اصلی هر توییت (`hashtags`)\n",
    "   - متن پیش‌پردازش شده (`clean_text`)\n",
    "   - متن توییت‌ها بدون هشتگ (`removed_hashtags`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1337 tweets with hashtags\n"
     ]
    }
   ],
   "source": [
    "texts_df['clean_text'] = texts_df['text'].apply(preprocess_text)\n",
    "texts_df['hashtags'] = texts_df['text'].apply(extract_hashtags)\n",
    "texts_df['has_hashtag'] = texts_df['hashtags'].apply(lambda x: len(x) > 0)\n",
    "texts_df['removed_hashtags'] = texts_df['clean_text'].apply(lambda x: re.sub(r'#(\\w+)', '', x))\n",
    "\n",
    "# Split data into tweets with and without hashtags\n",
    "tweets_with_hashtags = texts_df[texts_df['has_hashtag']]\n",
    "tweets_without_hashtags = texts_df[~texts_df['has_hashtag']]\n",
    "print(f\"There are {len(tweets_with_hashtags)} tweets with hashtags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در   داده‌ها، ۱۳۳۷ توییت با هشتگ وجود دارد. براساس انچه در تمرین خواسته شده، ۲۰٪ از آن‌ها یعنی ۲۶۷ توییت  برای آموزش انتخاب  می‌شود\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.20\n",
    "tweets_with_hashtags_train = tweets_with_hashtags.sample(frac=train_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>preprocess_texts</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>has_hashtag</th>\n",
       "      <th>removed_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>RT @Ftm_Jahani: #صداوسيما پاسخ گو باشد\\r\\nبرای رفتار غیر اخلاقی کارشناس آقای خسروی چه دارید بگویید؟\\r\\nدر خصوص این اهانت باید از اقای #سعید_محمد…</td>\n",
       "      <td>صداوسیما پاسخ‌گو باشدبرای رفتار غیر اخلاقی کارشناس آقای خسروی چه دارید بگوییددر خصوص این اهانت باید از اقای سعید محمد</td>\n",
       "      <td>#صداوسيما پاسخ گو باشدبرای رفتار غیر اخلاقی کارشناس آقای خسروی چه دارید بگوییددر خصوص این اهانت باید از اقای #سعید_محمد</td>\n",
       "      <td>[صداوسيما, سعید_محمد]</td>\n",
       "      <td>True</td>\n",
       "      <td>پاسخ گو باشدبرای رفتار غیر اخلاقی کارشناس آقای خسروی چه دارید بگوییددر خصوص این اهانت باید از اقای</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>نمیدونم چندمین رای میشه\\r\\nI vote #Dynamite for #BestMusicVideo at the #iHeartAwards \\r\\n@BTS_twt</td>\n",
       "      <td>نمیدونم چندمین رای میشهi voe dynamie fo besmusicvideo a he iheaawads</td>\n",
       "      <td>نمیدونم چندمین رای میشهi voe #dynamie fo #besmusicvideo a he #iheaawads</td>\n",
       "      <td>[Dynamite, BestMusicVideo, iHeartAwards]</td>\n",
       "      <td>True</td>\n",
       "      <td>نمیدونم چندمین رای میشهi voe  fo  a he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>RT @Mozafari_hadi70: از جهت وجه خارجی هم انتخابات و مشارکت مردم نشان دهنده اقتدار ملی است.\\r\\n#دیار_صددرصد_رای_آری</td>\n",
       "      <td>از جهت وجه خارجی هم انتخابات و مشارکت مردم نشان‌دهنده اقتدار ملی است دیار صددرصد رای آری</td>\n",
       "      <td>از جهت وجه خارجی هم انتخابات و مشارکت مردم نشان دهنده اقتدار ملی است#دیار_صددرصد_رای_آری</td>\n",
       "      <td>[دیار_صددرصد_رای_آری]</td>\n",
       "      <td>True</td>\n",
       "      <td>از جهت وجه خارجی هم انتخابات و مشارکت مردم نشان دهنده اقتدار ملی است</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>RT @sarbazetwitt: فوری\\r\\nدکتر #سعید_محمد طی تماس تلفنی از #سعید_جلیلی جهت ثبت نام در انتخابات دعوت بعمل آورد. https://t.co/9NkIFcfwEH</td>\n",
       "      <td>فوریدکتر سعید محمد طی تماس تلفنی از سعید جلیلی جهت ثبت‌نام در انتخابات دعوت بعمل آورد</td>\n",
       "      <td>فوریدکتر #سعید_محمد طی تماس تلفنی از #سعید_جلیلی جهت ثبت نام در انتخابات دعوت بعمل آورد</td>\n",
       "      <td>[سعید_محمد, سعید_جلیلی]</td>\n",
       "      <td>True</td>\n",
       "      <td>فوریدکتر  طی تماس تلفنی از  جهت ثبت نام در انتخابات دعوت بعمل آورد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>با چراغی همه جا گشتم وگشتم در شهر هیچ کس ... هیچ کس اینجا به تو مانند نشد #وحدت_برای_مردم #دوباره_ایثار #قالیباف https://t.co/zMPCx2GmlV</td>\n",
       "      <td>با چراغی همه‌جا گشتم وگشتم در شهر هیچ‌کس هیچ‌کس اینجا به تو مانند نشد وحدت برای مردم دوباره ایثار قالیباف</td>\n",
       "      <td>با چراغی همه جا گشتم وگشتم در شهر هیچ کس هیچ کس اینجا به تو مانند نشد #وحدت_برای_مردم #دوباره_ایثار #قالیباف</td>\n",
       "      <td>[وحدت_برای_مردم, دوباره_ایثار, قالیباف]</td>\n",
       "      <td>True</td>\n",
       "      <td>با چراغی همه جا گشتم وگشتم در شهر هیچ کس هیچ کس اینجا به تو مانند نشد</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  \\\n",
       "7            7   \n",
       "8            8   \n",
       "10          10   \n",
       "11          11   \n",
       "13          13   \n",
       "\n",
       "                                                                                                                                                 text  \\\n",
       "7   RT @Ftm_Jahani: #صداوسيما پاسخ گو باشد\\r\\nبرای رفتار غیر اخلاقی کارشناس آقای خسروی چه دارید بگویید؟\\r\\nدر خصوص این اهانت باید از اقای #سعید_محمد…   \n",
       "8                                                   نمیدونم چندمین رای میشه\\r\\nI vote #Dynamite for #BestMusicVideo at the #iHeartAwards \\r\\n@BTS_twt   \n",
       "10                                 RT @Mozafari_hadi70: از جهت وجه خارجی هم انتخابات و مشارکت مردم نشان دهنده اقتدار ملی است.\\r\\n#دیار_صددرصد_رای_آری   \n",
       "11             RT @sarbazetwitt: فوری\\r\\nدکتر #سعید_محمد طی تماس تلفنی از #سعید_جلیلی جهت ثبت نام در انتخابات دعوت بعمل آورد. https://t.co/9NkIFcfwEH   \n",
       "13           با چراغی همه جا گشتم وگشتم در شهر هیچ کس ... هیچ کس اینجا به تو مانند نشد #وحدت_برای_مردم #دوباره_ایثار #قالیباف https://t.co/zMPCx2GmlV   \n",
       "\n",
       "                                                                                                         preprocess_texts  \\\n",
       "7   صداوسیما پاسخ‌گو باشدبرای رفتار غیر اخلاقی کارشناس آقای خسروی چه دارید بگوییددر خصوص این اهانت باید از اقای سعید محمد   \n",
       "8                                                    نمیدونم چندمین رای میشهi voe dynamie fo besmusicvideo a he iheaawads   \n",
       "10                               از جهت وجه خارجی هم انتخابات و مشارکت مردم نشان‌دهنده اقتدار ملی است دیار صددرصد رای آری   \n",
       "11                                  فوریدکتر سعید محمد طی تماس تلفنی از سعید جلیلی جهت ثبت‌نام در انتخابات دعوت بعمل آورد   \n",
       "13              با چراغی همه‌جا گشتم وگشتم در شهر هیچ‌کس هیچ‌کس اینجا به تو مانند نشد وحدت برای مردم دوباره ایثار قالیباف   \n",
       "\n",
       "                                                                                                                 clean_text  \\\n",
       "7   #صداوسيما پاسخ گو باشدبرای رفتار غیر اخلاقی کارشناس آقای خسروی چه دارید بگوییددر خصوص این اهانت باید از اقای #سعید_محمد   \n",
       "8                                                   نمیدونم چندمین رای میشهi voe #dynamie fo #besmusicvideo a he #iheaawads   \n",
       "10                                 از جهت وجه خارجی هم انتخابات و مشارکت مردم نشان دهنده اقتدار ملی است#دیار_صددرصد_رای_آری   \n",
       "11                                  فوریدکتر #سعید_محمد طی تماس تلفنی از #سعید_جلیلی جهت ثبت نام در انتخابات دعوت بعمل آورد   \n",
       "13             با چراغی همه جا گشتم وگشتم در شهر هیچ کس هیچ کس اینجا به تو مانند نشد #وحدت_برای_مردم #دوباره_ایثار #قالیباف   \n",
       "\n",
       "                                    hashtags  has_hashtag  \\\n",
       "7                      [صداوسيما, سعید_محمد]         True   \n",
       "8   [Dynamite, BestMusicVideo, iHeartAwards]         True   \n",
       "10                     [دیار_صددرصد_رای_آری]         True   \n",
       "11                   [سعید_محمد, سعید_جلیلی]         True   \n",
       "13   [وحدت_برای_مردم, دوباره_ایثار, قالیباف]         True   \n",
       "\n",
       "                                                                                        removed_hashtags  \n",
       "7    پاسخ گو باشدبرای رفتار غیر اخلاقی کارشناس آقای خسروی چه دارید بگوییددر خصوص این اهانت باید از اقای   \n",
       "8                                                                نمیدونم چندمین رای میشهi voe  fo  a he   \n",
       "10                                  از جهت وجه خارجی هم انتخابات و مشارکت مردم نشان دهنده اقتدار ملی است  \n",
       "11                                    فوریدکتر  طی تماس تلفنی از  جهت ثبت نام در انتخابات دعوت بعمل آورد  \n",
       "13                              با چراغی همه جا گشتم وگشتم در شهر هیچ کس هیچ کس اینجا به تو مانند نشد     "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_with_hashtags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>preprocess_texts</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>has_hashtag</th>\n",
       "      <th>removed_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>هدف من پیدا کردن ایران ستیزان بود که شما رو یافتم \\r\\nحالا شما از پشت لباس پادشاهی دوست بیا بیرون چون طرفداران پادشاهی… https://t.co/ZKXhxrtVZU</td>\n",
       "      <td>هدف من پیدا کردن ایران ستیزان بود که شما رو یافتم حالا شما از پشت لباس پادشاهی دوست بیا بیرون چون طرفداران پادشاهی</td>\n",
       "      <td>هدف من پیدا کردن ایران ستیزان بود که شما رو یافتم حالا شما از پشت لباس پادشاهی دوست بیا بیرون چون طرفداران پادشاهی</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>هدف من پیدا کردن ایران ستیزان بود که شما رو یافتم حالا شما از پشت لباس پادشاهی دوست بیا بیرون چون طرفداران پادشاهی</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@reise_ghabile ظهر شمام بخیر</td>\n",
       "      <td>ظهر شمام بخیر</td>\n",
       "      <td>ظهر شمام بخیر</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>ظهر شمام بخیر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>دوست پسر خلبان کجا میفروخن؟</td>\n",
       "      <td>دوست پسر خلبان کجا میفروخن</td>\n",
       "      <td>دوست پسر خلبان کجا میفروخن</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>دوست پسر خلبان کجا میفروخن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>@HoseinMr007 خب اونجا زندگی میکنیم</td>\n",
       "      <td>خب اونجا زندگی می‌کنیم</td>\n",
       "      <td>خب اونجا زندگی میکنیم</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>خب اونجا زندگی میکنیم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @debianstable1: صبحا که میخوان منو از خواب بیدار کنن... https://t.co/ZOLx1KOqTW</td>\n",
       "      <td>صبحا که میخوان منو از خواب بیدار کنن</td>\n",
       "      <td>صبحا که میخوان منو از خواب بیدار کنن</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>صبحا که میخوان منو از خواب بیدار کنن</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0           0   \n",
       "1           1   \n",
       "2           2   \n",
       "3           3   \n",
       "4           4   \n",
       "\n",
       "                                                                                                                                              text  \\\n",
       "0  هدف من پیدا کردن ایران ستیزان بود که شما رو یافتم \\r\\nحالا شما از پشت لباس پادشاهی دوست بیا بیرون چون طرفداران پادشاهی… https://t.co/ZKXhxrtVZU   \n",
       "1                                                                                                                     @reise_ghabile ظهر شمام بخیر   \n",
       "2                                                                                                                      دوست پسر خلبان کجا میفروخن؟   \n",
       "3                                                                                                               @HoseinMr007 خب اونجا زندگی میکنیم   \n",
       "4                                                               RT @debianstable1: صبحا که میخوان منو از خواب بیدار کنن... https://t.co/ZOLx1KOqTW   \n",
       "\n",
       "                                                                                                     preprocess_texts  \\\n",
       "0  هدف من پیدا کردن ایران ستیزان بود که شما رو یافتم حالا شما از پشت لباس پادشاهی دوست بیا بیرون چون طرفداران پادشاهی   \n",
       "1                                                                                                       ظهر شمام بخیر   \n",
       "2                                                                                          دوست پسر خلبان کجا میفروخن   \n",
       "3                                                                                              خب اونجا زندگی می‌کنیم   \n",
       "4                                                                                صبحا که میخوان منو از خواب بیدار کنن   \n",
       "\n",
       "                                                                                                           clean_text  \\\n",
       "0  هدف من پیدا کردن ایران ستیزان بود که شما رو یافتم حالا شما از پشت لباس پادشاهی دوست بیا بیرون چون طرفداران پادشاهی   \n",
       "1                                                                                                       ظهر شمام بخیر   \n",
       "2                                                                                          دوست پسر خلبان کجا میفروخن   \n",
       "3                                                                                               خب اونجا زندگی میکنیم   \n",
       "4                                                                                صبحا که میخوان منو از خواب بیدار کنن   \n",
       "\n",
       "  hashtags  has_hashtag  \\\n",
       "0       []        False   \n",
       "1       []        False   \n",
       "2       []        False   \n",
       "3       []        False   \n",
       "4       []        False   \n",
       "\n",
       "                                                                                                     removed_hashtags  \n",
       "0  هدف من پیدا کردن ایران ستیزان بود که شما رو یافتم حالا شما از پشت لباس پادشاهی دوست بیا بیرون چون طرفداران پادشاهی  \n",
       "1                                                                                                       ظهر شمام بخیر  \n",
       "2                                                                                          دوست پسر خلبان کجا میفروخن  \n",
       "3                                                                                               خب اونجا زندگی میکنیم  \n",
       "4                                                                                صبحا که میخوان منو از خواب بیدار کنن  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_without_hashtags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## مدل ها"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p>پیاده‌سازی مدل <span dir=\"ltr\">Naive Bayse</span> با تعبیه‌سازی کلمات</p>\n",
    "<p>در این بخش ابتدا یک   <span dir=\"ltr\">CountVectorizer</span> از کتابخانه  <span dir=\"ltr\">sklearn</span>  ایجاد میشود که یرای تعبیه کردن استفاده میشود، سپس در متغیر  <span dir=\"ltr\">`y_train`</span> لیبل ها قرار دارند، اولین هشتگ به عنوان لیبل انتخاب می‌شود\n",
    "</p>\n",
    "و سپس مدل اماده کتابخانه اموزش داده می‌شود."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data for Naive Bayes\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(tweets_with_hashtags_train['clean_text'])\n",
    "\n",
    "# Create labels from hashtags (using the first hashtag for simplicity)\n",
    "y_train = tweets_with_hashtags_train['hashtags'].apply(lambda x: x[0] if x else '')\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predict_hashtags_nb`: تابع پیش‌بینی هشتگ با Naive Bayes\n",
    "- ورودی: متن توییت\n",
    "- خروجی: سه هشتگ پیشنهادی با بالاترین احتمال\n",
    "\n",
    "<p>در این قطعه کد، ابتدا متن ورودی با استفاده از <span dir=\"ltr\">vectorizer</span> به یک نمایش برداری تبدیل می‌شود. سپس تابع <span dir=\"ltr\">predict_proba</span> از مدل <span dir=\"ltr\">nb_model</span> فراخوانی می‌شود تا احتمال تعلق متن به هر یک از کلاس‌ها (هشتگ‌ها) محاسبه گردد. در ادامه، این احتمالات مرتب‌سازی می‌شوند و شاخص‌های مربوط به <span dir=\"ltr\">top_n</span> هشتگ با بالاترین احتمال انتخاب می‌شوند. در نهایت، با استفاده از این شاخص‌ها، نام هشتگ‌های متناظر از لیست کلاس‌های مدل (<span dir=\"ltr\">nb_model.classes_</span>) استخراج شده و به‌عنوان خروجی بازگردانده می‌شوند.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_hashtags_nb(text, top_n=3):\n",
    "    \"\"\"Predict top N hashtags using Naive Bayes\"\"\"\n",
    "    text_vector = vectorizer.transform([text])\n",
    "    probs = nb_model.predict_proba(text_vector)\n",
    "    top_indices = np.argsort(probs[0])[-top_n:][::-1]\n",
    "    return [nb_model.classes_[i] for i in top_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p> پیاده سازی الگوریتم <span dir=\"ltr\">Naive Bayse</span> با کلاس و احتساب احتمالات  </p>\n",
    "\n",
    "در پیاده‌سازی الگوریتم ناییو بیس، دو نوع احتمال اصلی محاسبه می‌شود: \n",
    "\n",
    "1. **احتمال پیشین**: نشان‌دهنده فراوانی نسبی هر هشتگ در داده‌های آموزشی است.\n",
    "2. **احتمال شرطی**: نشان می‌دهد که یک کلمه خاص چقدر احتمال دارد در متونی که به یک هشتگ خاص تعلق دارند، ظاهر شود. \n",
    "\n",
    "این احتمالات به مدل کمک می‌کنند تا هشتگ‌های مناسب برای متون جدید را پیش‌بینی کند.\n",
    "\n",
    "##### ساختار کلاس\n",
    "در این پیاده‌سازی، سه متغیر اصلی تعریف شده است:\n",
    "- `word_probs`: دیکشنری برای نگهداری احتمال شرطی هر کلمه برای هر هشتگ.\n",
    "- `hashtag_probs`: دیکشنری برای نگهداری احتمال پیشین هر هشتگ.\n",
    "- `vocab`: مجموعه‌ای از تمام کلمات مشاهده شده در متون.\n",
    "- `word_counts`: دیکشنری برای نگهداری تعداد تکرار کلمات برای هر هشتگ.\n",
    "- `hashtag_counts`: دیکشنری برای نگهداری تعداد تکرار هر هشتگ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### توابع "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### تابع پیش‌پردازش (`preprocess`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در این تابع، متن ورودی به کلمات جداگانه تقسیم می‌شود:\n",
    "- متن به حروف کوچک تبدیل می‌گردد\n",
    "- بر اساس فاصله‌ها به کلمات مجزا تفکیک می‌شود\n",
    "- لیستی از کلمات برگردانده می‌شود"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### تابع `fit`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ورودی‌ها:**\n",
    "1. **متون آموزشی**: مجموعه‌ای از متون که هر کدام به یک یا چند هشتگ مرتبط هستند.\n",
    "2. **هشتگ‌های آموزشی**: لیستی از هشتگ‌ها که به هر متن آموزشی اختصاص داده شده‌اند.\n",
    "\n",
    "**فرآیند:**\n",
    "1. **شمارش و محاسبات اولیه**:\n",
    "   - **تعداد تکرار کلمات**: برای هر هشتگ، تعداد تکرار هر کلمه در متون مرتبط با آن هشتگ محاسبه می‌شود. این کار به مدل کمک می‌کند تا بفهمد کدام کلمات برای هر هشتگ مهم‌تر هستند.\n",
    "   - **تعداد تکرار هشتگ‌ها**: تعداد دفعاتی که هر هشتگ در مجموعه داده‌ها ظاهر می‌شود، شمارش می‌گردد.\n",
    "   - **به‌روزرسانی واژگان**: کلمات جدیدی که در متون آموزشی ظاهر می‌شوند به مجموعه واژگان مدل اضافه می‌شوند.\n",
    "\n",
    "2. **محاسبه احتمالات**:\n",
    "   - **احتمال پیشین هشتگ‌ها**: این احتمال نشان‌دهنده فراوانی نسبی هر هشتگ در کل مجموعه داده‌ها است و با تقسیم تعداد تکرار هر هشتگ بر کل تعداد هشتگ‌ها محاسبه می‌شود.\n",
    "   - **احتمال شرطی کلمات**: برای هر کلمه در هر هشتگ، احتمال شرطی آن کلمه با استفاده از هموارسازی لاپلاس محاسبه می‌شود. این احتمال نشان می‌دهد که یک کلمه خاص چقدر احتمال دارد در متونی که به یک هشتگ خاص تعلق دارند، ظاهر شود.\n",
    "\n",
    " **خروجی:**\n",
    "- **مدل آموزش‌دیده**: پس از اجرای این فرآیند، مدل بیز ساده آماده است تا با استفاده از احتمالات محاسبه‌شده، متون جدید را طبقه‌بندی کند و هشتگ‌های مناسب را پیش‌بینی نماید."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### تابع پیش‌بینی (`predict`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در این تابع، هشتگ‌های مناسب برای متن جدید پیش‌بینی می‌شوند:\n",
    "\n",
    "۱. **محاسبه امتیاز**:\n",
    "   - برای هر هشتگ، لگاریتم احتمال پیشین محاسبه می‌گردد\n",
    "   - برای هر کلمه در متن، لگاریتم احتمال شرطی به امتیاز اضافه می‌شود\n",
    "   - از لگاریتم برای جلوگیری از سرریز عددی استفاده می‌شود\n",
    "\n",
    "۲. **انتخاب هشتگ‌ها**:\n",
    "   - هشتگ‌ها بر اساس امتیاز مرتب می‌شوند\n",
    "   - تعداد مشخصی از بهترین هشتگ‌ها برگردانده می‌شوند"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source Code of Naive Bayse in class implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**نکات مهم پیاده‌سازی**\n",
    "- از هموارسازی لاپلاس برای جلوگیری از احتمالات صفر استفاده شده است یعنی وقتی مدل با کلمه جدیدی روبرو میشود تعداد کلمه جدید در دیتای ترین را به جای صفر یک در نظر میگیریم\n",
    "- محاسبات در فضای لگاریتمی انجام می‌شود تا از مشکلات عددی جلوگیری شود\n",
    "- امکان تنظیم تعداد هشتگ‌های پیشنهادی فراهم شده است"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "class CustomNaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.word_probs = {}  # احتمال هر کلمه برای هر هشتگ\n",
    "        self.hashtag_probs = {}  # احتمال پیشین هر هشتگ\n",
    "        self.vocab = set()  # مجموعه تمام کلمات\n",
    "        self.word_counts = {}  # نگهداری تعداد تکرار کلمات برای هر هشتگ\n",
    "        self.hashtag_counts = {}  # نگهداری تعداد تکرار هر هشتگ\n",
    "            \n",
    "    def get_hashtag_frequency(self, hashtag):\n",
    "        \"\"\"برگرداندن تعداد تکرار یک هشتگ در داده‌ها\"\"\"\n",
    "        return self.hashtag_counts.get(hashtag, 0)\n",
    "\n",
    "    def get_statistics(self):\n",
    "        \"\"\"\n",
    "        نمایش آمار کلی از داده‌های آموزشی\n",
    "        \"\"\"\n",
    "        stats = {\n",
    "            'total_hashtags': len(self.hashtag_probs),\n",
    "            'total_unique_words': len(self.vocab),\n",
    "            'hashtag_word_counts': {},\n",
    "            'top_words_per_hashtag': {},\n",
    "        }\n",
    "        \n",
    "        # محاسبه تعداد کلمات برای هر هشتگ\n",
    "        for hashtag in self.word_counts:\n",
    "            stats['hashtag_word_counts'][hashtag] = {\n",
    "                'total_words': sum(self.word_counts[hashtag].values()),\n",
    "                'unique_words': len(self.word_counts[hashtag]),\n",
    "                'frequency': self.hashtag_counts[hashtag]\n",
    "            }            \n",
    "            # پیدا کردن پرتکرارترین کلمات برای هر هشتگ\n",
    "            sorted_words = sorted(\n",
    "                self.word_counts[hashtag].items(), \n",
    "                key=lambda x: x[1], \n",
    "                reverse=True\n",
    "            )[:5]\n",
    "            stats['top_words_per_hashtag'][hashtag] = sorted_words\n",
    "            \n",
    "        print(stats)\n",
    "        return stats\n",
    "    \n",
    "    def print_statistics(self):\n",
    "        \"\"\"\n",
    "        چاپ آمار به صورت خوانا\n",
    "        \"\"\"\n",
    "        stats = self.get_statistics()\n",
    "        print(\"=== آمار کلی ===\")\n",
    "        print(f\"تعداد کل هشتگ‌های یکتا: {stats['total_hashtags']}\")\n",
    "        print(f\"تعداد کل کلمات یکتا: {stats['total_unique_words']}\")\n",
    "        \n",
    "        print(\"\\n=== آمار هر هشتگ ===\")\n",
    "        # مرتب‌سازی هشتگ‌ها بر اساس فراوانی\n",
    "        sorted_hashtags = sorted(\n",
    "            stats['hashtag_word_counts'].items(),\n",
    "            key=lambda x: x[1]['frequency'],\n",
    "            reverse=True\n",
    "        )\n",
    "        print(sorted_hashtags)\n",
    "        for hashtag, counts in sorted_hashtags:\n",
    "            print(f\"\\nهشتگ: {hashtag}\")\n",
    "            print(f\"تعداد تکرار: {counts['frequency']}\")\n",
    "            print(f\"تعداد کل کلمات: {counts['total_words']}\")\n",
    "            print(f\"تعداد کلمات یکتا: {counts['unique_words']}\")\n",
    "            print(\"پرتکرارترین کلمات:\")\n",
    "            for word, count in stats['top_words_per_hashtag'][hashtag]:\n",
    "                print(f\"    {word}: {count}\")\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        \"\"\"تبدیل متن به لیستی از کلمات\"\"\"\n",
    "        words = text.lower().split()\n",
    "        return words\n",
    "    \n",
    "    def fit(self, texts, hashtags):\n",
    "        \"\"\"آموزش مدل\"\"\"\n",
    "        self.word_counts = {}  # {hashtag: {word: count}}\n",
    "        self.hashtag_counts = {}  # {hashtag: count}\n",
    "        print(f\"Number of texts in train data: {len(texts)}\")\n",
    "        print(f\"Number of hashtags in train data: {len(hashtags)}\")\n",
    "        for text, hashtag in zip(texts, hashtags):\n",
    "            if not hashtag:  # اگر هشتگ خالی است\n",
    "                continue\n",
    "            # جدا سازی و اپدیت کلمات جدید در وکب\n",
    "            words = self.preprocess(text)\n",
    "            self.vocab.update(words)\n",
    "            # شمارش هشتگ‌ها\n",
    "            self.hashtag_counts[hashtag] = self.hashtag_counts.get(hashtag, 0) + 1\n",
    "            # شمارش کلمات برای هر هشتگ\n",
    "            if hashtag not in self.word_counts:\n",
    "                self.word_counts[hashtag] = {}\n",
    "            # حساب کلمات هر کلاس\n",
    "            for word in words:\n",
    "                if not word:  # اگر کلمه خالی است\n",
    "                    continue\n",
    "                self.word_counts[hashtag][word] = self.word_counts[hashtag].get(word, 0) + 1\n",
    "        print(f\"Number of unique hashtags: {len(self.hashtag_counts)}\")\n",
    "        print(f\"Number of hashtags with word counts: {len(self.word_counts)}\")\n",
    "        # محاسبه احتمالات\n",
    "        total_hashtags = sum(self.hashtag_counts.values())\n",
    "        # احتمال پیشین هر هشتگ\n",
    "        for hashtag, count in self.hashtag_counts.items():\n",
    "            self.hashtag_probs[hashtag] = count / total_hashtags\n",
    "        # احتمال هر کلمه برای هر هشتگ (با هموارسازی لاپلاس)\n",
    "        for hashtag in self.hashtag_counts:\n",
    "            self.word_probs[hashtag] = {}\n",
    "            total_words = sum(self.word_counts[hashtag].values()) + len(self.vocab)\n",
    "            for word in self.vocab:\n",
    "                count = self.word_counts[hashtag].get(word, 0) + 1  # هموارسازی لاپلاس\n",
    "                self.word_probs[hashtag][word] = count / total_words\n",
    "    \n",
    "    def predict(self, text, top_n=3):\n",
    "        \"\"\"پیش‌بینی هشتگ‌های مناسب\"\"\"\n",
    "        words = self.preprocess(text)\n",
    "        scores = {}\n",
    "        \n",
    "        # محاسبه امتیاز هر هشتگ\n",
    "        for hashtag in self.hashtag_probs:\n",
    "            # شروع با لگاریتم احتمال پیشین\n",
    "            score = np.log(self.hashtag_probs[hashtag])\n",
    "            \n",
    "            # اضافه کردن لگاریتم احتمال کلمات\n",
    "            for word in words:\n",
    "                if word in self.vocab:\n",
    "                    score += np.log(self.word_probs[hashtag].get(word, 1/len(self.vocab)))\n",
    "            \n",
    "            scores[hashtag] = score\n",
    "        \n",
    "        # انتخاب بهترین هشتگ‌ها\n",
    "        sorted_hashtags = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        return [h[0] for h in sorted_hashtags[:top_n]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts in train data: 267\n",
      "Number of hashtags in train data: 267\n",
      "Number of unique hashtags: 120\n",
      "Number of hashtags with word counts: 120\n"
     ]
    }
   ],
   "source": [
    "custom_nb = CustomNaiveBayes()\n",
    "train_texts = tweets_with_hashtags_train['removed_hashtags']\n",
    "train_hashtags = tweets_with_hashtags_train['hashtags'].apply(lambda x: x[0] if x else '')\n",
    "custom_nb.fit(train_texts, train_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_hashtags_custom_nb(text, top_n=4):      \n",
    "    return custom_nb.predict(text, top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### پیاده‌سازی قوانین انجمنی کلاس (CAR)\n",
    "`generate_car_rules`: این تابع قوانین انجمنی را تولید می‌کند\n",
    "- پارامترها:\n",
    "  - min_support: حداقل پشتیبانی برای قوانین (پیش‌فرض: 0.001)\n",
    "  - min_confidence: حداقل اطمینان برای قوانین (پیش‌فرض: 0.5)\n",
    "- مراحل:\n",
    "  1. تبدیل متن‌ها به تراکنش‌ها\n",
    "  2. محاسبه مجموعه کلمات پرتکرار\n",
    "  3. تولید قوانین با اطمینان بالا\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تولید قوانین انجمنی کلاس (`generate_car_rules`):\n",
    "- تبدیل متون به تراکنش‌ها: هر متن به مجموعه‌ای از کلمات تبدیل می‌شود و هشتگ‌های مربوط به آن به عنوان برچسب در نظر گرفته می‌شوند\n",
    "- تولید مجموعه‌های اقلام پرتکرار: تعداد تکرار هر کلمه در تراکنش‌ها محاسبه می‌شود و کلماتی که فراوانی آن‌ها از حداقل پشتیبانی تعیین‌شده بیشتر است، انتخاب می‌شوند.\n",
    "- تولید قوانین: برای هر کلمه پرتکرار، احتمال وقوع آن با هر هشتگ محاسبه می‌شود. اگر اطمینان این احتمال از حداقل اطمینان تعیین‌شده بیشتر باشد، قانون مربوطه به لیست قوانین اضافه می‌شود."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_car_rules(texts_df, min_support=0.001, min_confidence=0.7):\n",
    "    \"\"\"Generate Class Association Rules\"\"\"\n",
    "    # Convert texts to transactions\n",
    "    transactions = []\n",
    "    labels = []\n",
    "    for _, row in texts_df.iterrows():\n",
    "        words = set(row['clean_text'].split())\n",
    "        hashtags = set(row['hashtags'])\n",
    "        if hashtags:\n",
    "            transactions.append(words)\n",
    "            labels.append(list(hashtags)[0])  # Use first hashtag as label\n",
    "    # Generate frequent itemsets\n",
    "    word_counts = {}\n",
    "    for transaction in transactions:\n",
    "        for word in transaction:\n",
    "            word_counts[word] = word_counts.get(word, 0) + 1\n",
    "    # Filter by support\n",
    "    frequent_words = {word: count for word, count in word_counts.items() \n",
    "                     if count/len(transactions) >= min_support}\n",
    "    # Generate rules\n",
    "    rules = []\n",
    "    for word in frequent_words:\n",
    "        for label in set(labels):\n",
    "            support_word = sum(1 for t in transactions if word in t)\n",
    "            support_label = sum(1 for l in labels if l == label)\n",
    "            support_both = sum(1 for t, l in zip(transactions, labels) \n",
    "                             if word in t and l == label)\n",
    "            \n",
    "            confidence = support_both / support_word if support_word > 0 else 0\n",
    "            \n",
    "            if confidence >= min_confidence:\n",
    "                rules.append((word, label, confidence))\n",
    "    return rules\n",
    "car_rules = generate_car_rules(tweets_with_hashtags_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('اهالی', 'رستم_قاسمی', 1.0),\n",
       " ('منتظرت', 'رستم_قاسمی', 1.0),\n",
       " ('فارس', 'رستم_قاسمی', 1.0),\n",
       " ('آرمی', 'BestMusicVideo', 1.0),\n",
       " ('#besmusicvideo', 'BestMusicVideo', 0.8),\n",
       " ('عقبیمi', 'BestMusicVideo', 1.0),\n",
       " ('میدونستین', 'BestMusicVideo', 1.0),\n",
       " ('#dynamie', 'BestMusicVideo', 0.8),\n",
       " ('تئوری', 'محسن_رضایی', 1.0),\n",
       " ('اقتصادی', 'محسن_رضایی', 0.7777777777777778)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_rules[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "پیش‌بینی هشتگ‌ها با استفاده از قوانین انجمنی کلاس (`predict_hashtags_car`):\n",
    "- تبدیل متن به مجموعه کلمات: متن ورودی با اسپلیت به مجموعه‌ای از کلمات تبدیل می‌شود\n",
    "- پیش‌بینی هشتگ‌ها: برای هر کلمه در متن، اگر در قوانین موجود باشد، هشتگ‌های مربوطه با اطمینان آن‌ها به لیست پیش‌بینی‌ها اضافه می‌شود.\n",
    "- مرتب‌سازی و انتخاب بهترین‌ها: پیش‌بینی‌ها بر اساس اطمینان مرتب شده و تعداد مشخصی از بهترین هشتگ‌ها برگردانده می‌شود"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_hashtags_car(text, rules, top_n=3):\n",
    "    \"\"\"Predict top N hashtags using CAR rules\"\"\"\n",
    "    words = set(text.split())\n",
    "    predictions = []\n",
    "    \n",
    "    for word, label, confidence in rules:\n",
    "        if word in words:\n",
    "            predictions.append((label, confidence))\n",
    "    \n",
    "    # Sort by confidence and return top N\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [pred[0] for pred in predictions[:top_n]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## مقایسه و ارزیابی و تحلیل نهایی \n",
    "\n",
    "`compare_methods`: مقایسه نتایج دو روش\n",
    "- نمایش متن اصلی\n",
    "- نمایش پیش‌بینی‌های Naive Bayes\n",
    "- نمایش پیش‌بینی‌های CAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_methods(test_text , original_text,original_tweet_tupple):\n",
    "    \"\"\"Compare hashtag predictions from both methods\"\"\"\n",
    "    print(\"Original text:\", original_text)\n",
    "    print(f\"Original Hashtag: {original_tweet_tupple[1]['hashtags'][0]}\")\n",
    "    print(f\"\\nNumber of original hashtag in train data: {custom_nb.get_hashtag_frequency(original_tweet_tupple[1]['hashtags'][0])}\")\n",
    "    print(\"\\n\\t- Naive Bayes predictions:\", predict_hashtags_custom_nb(test_text))\n",
    "    print(\"\\n\\t- Naive Bayes predictions Vectorized(Sklearn Model):\", predict_hashtags_nb(test_text))\n",
    "    print(\"\\n\\t- CAR predictions:\", predict_hashtags_car(preprocess_text(test_text), car_rules))\n",
    "    print(\"================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: امروز رژیم آخوندی در چنان تنگنای مرگباری گرفتار شده که در تاریخچه این رژیم به ‌ندرت سابقه دارد#ایران #ianegimechang\n",
      "Original Hashtag: ایران\n",
      "\n",
      "Number of original hashtag in train data: 2\n",
      "\n",
      "\t- Naive Bayes predictions: ['محسن_رضایی', 'SabaHungerStrike', 'رئیسی_متشکریم', 'آقامحسن_ایران']\n",
      "\n",
      "\t- Naive Bayes predictions Vectorized(Sklearn Model): ['محسن_رضایی', 'SabaHungerStrike', 'رئیسی_متشکریم']\n",
      "\n",
      "\t- CAR predictions: ['سیرک_انتخابات']\n",
      "================================================\n",
      "Original text: مرد اقدام و تحول از هیچ تلاش و تکاپویی برای حل مشکلات اقشار ضعیف و آسیب پذیر فروگذار نخواهد کرد#اقدام_و_تحول#محسن_رض\n",
      "Original Hashtag: اقدام_و_تحول\n",
      "\n",
      "Number of original hashtag in train data: 10\n",
      "\n",
      "\t- Naive Bayes predictions: ['محسن_رضایی', 'آقامحسن_ایران', 'رئیسی_متشکریم', 'اقدام_و_تحول']\n",
      "\n",
      "\t- Naive Bayes predictions Vectorized(Sklearn Model): ['محسن_رضایی', 'SabaHungerStrike', 'اقدام_و_تحول']\n",
      "\n",
      "\t- CAR predictions: ['رئیسی_متشکریم', 'رئیسی_متشک']\n",
      "================================================\n",
      "Original text: #سعید_محمد #دولت_جوان_انقلابی تا اخر ایستاده ایم 🇮🇷🇮🇷\n",
      "Original Hashtag: سعید_محمد\n",
      "\n",
      "Number of original hashtag in train data: 5\n",
      "\n",
      "\t- Naive Bayes predictions: ['سعید_محمد', 'محسن_رضایی', 'آقامحسن_ایران', 'دولت_اقدام']\n",
      "\n",
      "\t- Naive Bayes predictions Vectorized(Sklearn Model): ['سعید_محمد', 'محسن_رضایی', 'آقامحسن_ایران']\n",
      "\n",
      "\t- CAR predictions: ['سعید_محمد', 'سعید_محمد', 'سعید_محمد']\n",
      "================================================\n",
      "Original text: دعوت شدم برای تزریق آزمایشی واکسن کرونای انستیتو پاستورامیدوارم ایمنی لازم در برابر ویروس #کرونا ایجاد کنه هر چه\n",
      "Original Hashtag: کرونا\n",
      "\n",
      "Number of original hashtag in train data: 2\n",
      "\n",
      "\t- Naive Bayes predictions: ['کرونا', 'SabaHungerStrike', 'محسن_رضایی', 'رئیسی_متشکریم']\n",
      "\n",
      "\t- Naive Bayes predictions Vectorized(Sklearn Model): ['کرونا', 'SabaHungerStrike', 'محسن_رضایی']\n",
      "\n",
      "\t- CAR predictions: ['کرونا', 'کرونا', 'کرونا']\n",
      "================================================\n",
      "Original text: سختیهای عشایر و پا در رکاب انقلاب ماندن#ذخایر_انقلاب\n",
      "Original Hashtag: ذخایر_انقلاب\n",
      "\n",
      "Number of original hashtag in train data: 1\n",
      "\n",
      "\t- Naive Bayes predictions: ['رئیسی_متشکریم', 'محسن_رضایی', 'اقدام_و_تحول', 'آقامحسن_ایران']\n",
      "\n",
      "\t- Naive Bayes predictions Vectorized(Sklearn Model): ['رئیسی_متشکریم', 'محسن_رضایی', 'SabaHungerStrike']\n",
      "\n",
      "\t- CAR predictions: ['ذخایر_انقلاب']\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "test_tweets = tweets_with_hashtags.sample(n=5)\n",
    "test_tweets_without_hashtags = test_tweets['removed_hashtags']\n",
    "for tweet_text , original_tweet_tupple in zip(test_tweets_without_hashtags, list(test_tweets.iterrows())):\n",
    "     compare_methods(tweet_text, original_tweet_tupple[1]['clean_text'] , original_tweet_tupple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **تحلیل**\n",
    "اولا بنابر ارتباط مستقیم تعداد نمونه ها در داده اموزشی تعداد هشتگ ها در تست ها تعداد هشتگ مربوطه در داده اموزشی نشان داده شده است\n",
    "\n",
    "نتایج نشان می‌دهد که عملکرد مدل‌های پیش‌بینی هشتگ بسته فراوانی هشتگ در داده‌های آموزشی متفاوت است. در مواردی که هشتگ اصلی دارای فراوانی بالایی در داده‌های آموزشی بوده و یا ارتباط معنایی قوی با کلمات موجود در متن دارد، دقت پیش‌بینی‌ها افزایش می‌یابد. در مقابل، توییت هایی که هشتگ‌های آن‌ها در داده‌های آموزشی نادر هستند یا از نظر معنایی ارتباط مستقیمی با کلمات متن ندارند (خصوصا در مدل ناییو بیس با وکتورها)، چالش‌برانگیز بوده و منجر به پیش‌بینی‌های نادرستی می‌شوند.\n",
    "پس چون مدل های ناییو بیس، براساس احتمالات و فراوانی کلمات هستند، در مواجهه با کلمات جدید ضعیف عمل می کنند.\n",
    "\n",
    "<p> مدل  <span dir=\"ltr\">CAR</span>  نیز زمانی عملکرد مطلوبی دارد که کلمات کلیدی مشخصی در توییت تست وجود داشته باشند که در داده‌های آموزشی، قوانین قوی و با اطمینان بالایی را برای یک هشتگ خاص ایجاد کرده باشند. </p>\n",
    "\n",
    "\n",
    "- ✅ هشتگ اول SabaHungerStrike : هشتگ موردنظر در داده‌ی آموزشی با فراوانی زیادی (۲۲ بار) مشاهده شده است پس احتمال پریدکت صحیح هشتگ توسظ هر سه مدل به‌درستی توسط انجام شده است.\n",
    "- ❌ سوم هشتگ 엑소:  در این مورد اما هشتگ موردنظر با فراوانی پایین (۵ بار) در داده‌ی آموزشی وجود داشته که می تواند دلیل اصلی خطا در پیش بینی باشد همچنین متن شامل واژگان غیر فارسی است که در مدل وکتورکردن داده ها نیز ممکن است احتمال خظا را بالا ببرد.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.368270332187858\n",
      "Naive Bayes Accuracy Vectorized(Sklearn function): 0.43585337915234823\n",
      "CAR Accuracy: 0.28121420389461627\n"
     ]
    }
   ],
   "source": [
    "def evaluate_methods(test_data):\n",
    "    \"\"\"Evaluate both methods on test data\"\"\"\n",
    "    nb_correct = car_correct = nb_correct_vectorized= total = 0\n",
    "    \n",
    "    for _, row in test_data.iterrows():\n",
    "        true_hashtags = set(row['hashtags'])\n",
    "        if not true_hashtags:\n",
    "            continue\n",
    "            \n",
    "        nb_predictions = set(predict_hashtags_custom_nb(row['clean_text']))\n",
    "        nb_predictions_vectorized = set(predict_hashtags_nb(row['clean_text']))\n",
    "        car_predictions = set(predict_hashtags_car(row['clean_text'], car_rules))\n",
    "        \n",
    "        nb_correct += len(true_hashtags.intersection(nb_predictions))\n",
    "        nb_correct_vectorized += len(true_hashtags.intersection(nb_predictions_vectorized))\n",
    "        car_correct += len(true_hashtags.intersection(car_predictions))\n",
    "        total += len(true_hashtags)\n",
    "    \n",
    "    print(\"Naive Bayes Accuracy:\", nb_correct/total if total > 0 else 0)\n",
    "    print(\"Naive Bayes Accuracy Vectorized(Sklearn function):\", nb_correct_vectorized/total if total > 0 else 0)\n",
    "    print(\"CAR Accuracy:\", car_correct/total if total > 0 else 0)\n",
    "\n",
    "# Evaluate on remaining tweets with hashtags\n",
    "test_data = tweets_with_hashtags[~tweets_with_hashtags.index.isin(tweets_with_hashtags_train.index)]\n",
    "evaluate_methods(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hazm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
